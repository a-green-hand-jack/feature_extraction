# 模型训练初步摘要

**生成日期**: 2025-11-11
**状态**: 交叉验证进行中（80% 完成）

## 概览

本文档总结了在 SIF（模拟肠液）和 SGF（模拟胃液）数据集上进行肽稳定性预测的 5 折交叉验证结果。

### 数据集

1. **US9624268_cleaned**:
   - SIF：130 个样本，5 类
   - SGF：90 个样本，5 类（已过滤掉 40 个缺失标签的样本）

2. **sif_sgf_second_cleaned**:
   - SIF：558 个样本，4 类
   - SGF：558 个样本，4 类

### 评估的模型

- 逻辑回归（使用平衡类别权重）
- 随机森林（100 个估计器，平衡类别权重）
- XGBoost（100 个估计器，使用样本加权）

### 评估指标

- 准确率
- 精确率（宏平均）
- 召回率（宏平均）
- F1-分数（宏平均）
- AUC（一对多，宏平均）

---

## 结果

### 1. US9624268 - SIF（130 个样本，5 类）

| 模型 | 准确率 | 精确率 | 召回率 | F1-分数 | AUC |
|------|--------|--------|--------|---------|-----|
| 逻辑回归 | 0.377 ± 0.092 | 0.303 ± 0.069 | 0.308 ± 0.060 | 0.297 ± 0.064 | 0.631 ± 0.038 |
| 随机森林 | 0.446 ± 0.080 | 0.329 ± 0.096 | 0.331 ± 0.086 | 0.317 ± 0.087 | 0.635 ± 0.060 |
| **XGBoost** | **0.415 ± 0.074** | **0.323 ± 0.091** | **0.340 ± 0.081** | **0.324 ± 0.081** | **0.655 ± 0.024** |

**关键观察**：
- 随机森林达到最高准确率（0.446）
- XGBoost 显示最佳 AUC（0.655）和最低方差
- 所有模型在这个样本有限的 5 类问题上表现一般
- 由于类别不平衡（类别 4：仅 10 个样本），该数据集具有挑战性

---

### 2. US9624268 - SGF（90 个样本，5 类）

| 模型 | 准确率 | 精确率 | 召回率 | F1-分数 | AUC |
|------|--------|--------|--------|---------|-----|
| 逻辑回归 | 0.400 ± 0.099 | 0.319 ± 0.169 | 0.304 ± 0.116 | 0.294 ± 0.123 | 0.646 ± 0.090 |
| **随机森林** | **0.489 ± 0.099** | **0.332 ± 0.147** | **0.319 ± 0.098** | **0.301 ± 0.103** | **0.645 ± 0.148** |
| XGBoost | *（进行中）* | - | - | - | - |

**关键观察**：
- 随机森林优于逻辑回归
- 小样本量（90）使这成为极具挑战性的任务
- 指标的高方差表明对训练/测试分割的敏感性
- 严重的类别不平衡（类别 4：仅 4 个样本）

---

### 3. sif_sgf_second - SIF（558 个样本，4 类）

| 模型 | 准确率 | 精确率 | 召回率 | F1-分数 | AUC |
|------|--------|--------|--------|---------|-----|
| 逻辑回归 | 0.597 ± 0.030 | 0.432 ± 0.009 | 0.409 ± 0.028 | 0.396 ± 0.004 | 0.719 ± 0.052 |
| **随机森林** | **0.797 ± 0.040** | **0.494 ± 0.090** | **0.442 ± 0.044** | **0.453 ± 0.056** | **0.728 ± 0.052** |
| XGBoost | *（进行中）* | - | - | - | - |

**关键观察**：
- 随机森林显示强劲性能，准确率达 79.7%
- 更大的样本量（558）使模型训练更好
- 相比 US9624268 结果有显著改进
- 类别不平衡仍然存在（类别 4：64.7%，类别 2：2.87%）

---

### 4. sif_sgf_second - SGF（558 个样本，4 类）

| 模型 | 准确率 | 精确率 | 召回率 | F1-分数 | AUC |
|------|--------|--------|--------|---------|-----|
| 逻辑回归 | 0.573 ± 0.030 | 0.432 ± 0.022 | 0.432 ± 0.061 | 0.399 ± 0.027 | 0.730 ± 0.027 |
| **随机森林** | **0.790 ± 0.044** | **0.547 ± 0.120** | **0.475 ± 0.034** | **0.481 ± 0.045** | **0.796 ± 0.026** |
| XGBoost | *（进行中）* | - | - | - | - |

**关键观察**：
- 随机森林达到 79% 准确率和 79.6% AUC
- 整体表现最佳的数据集
- 比 SIF 更平衡的类别分布
- 与 SIF 数据集性能相似

---

## 初步洞察

### 数据集规模影响
- **更大的数据集表现显著更好**：sif_sgf_second（558 个样本）相比 US9624268（90-130 个样本）准确率提高约 35-40%
- 更大的数据集也显示指标方差更低（预测更稳定）

### 模型比较
- **随机森林**在所有数据集上始终优于其他模型
- **XGBoost** 显示出低方差的潜力（US9624268 SIF：AUC=0.655±0.024）
- **逻辑回归**作为可靠的基线，但被基于树的方法超越

### 类别不平衡处理
- 类别加权（`class_weight='balanced'`）有帮助，但不能完全解决不平衡问题
- 随机森林的集成特性使其对类别不平衡更稳健
- 非常小的类别（n<10）对所有模型仍然具有挑战性

### SIF vs SGF
- **SGF 预测**在较大数据集上往往略优于 SIF
- sif_sgf_second SGF：79% 准确率 vs SIF：79.7% 准确率（相似）
- US9624268 SGF：48.9% vs SIF：44.6%（由于规模小，两者都具有挑战性）

---

## 下一步

1. **完成 XGBoost 训练**在剩余数据集上
2. **迁移学习评估**：
   - 在 US9624268 上训练 → 在 sif_sgf_second 上测试
   - 在 sif_sgf_second 上训练 → 在 US9624268 上测试
   - 应用 5→4 类别映射以实现兼容性
3. **特征重要性分析**：
   - 识别关键分子描述符
   - 比较模型间的重要性
4. **可视化**：
   - 性能比较图表
   - 混淆矩阵
   - 迁移学习热图

---

## 技术说明

- 所有实验使用 5 折分层交叉验证
- 随机种子：42（用于可重现性）
- 特征集：1560 个特征（Morgan 指纹、Avalon 指纹、QED 属性、理化描述符）
- 类别标签重新映射为从 0 开始的索引，以兼容 XGBoost
- 缺失标签（-1）在训练前已过滤

---

*这是初步摘要。所有训练完成后将提供完整结果和可视化。*

