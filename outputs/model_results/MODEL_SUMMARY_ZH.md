# SIF/SGF 肽稳定性建模 - 完整分析报告

**生成日期**: 2025-11-12
**项目**: 使用分子指纹进行肽稳定性预测

---

## 执行摘要

本报告对 SIF（模拟肠液）和 SGF（模拟胃液）环境中的肽稳定性预测模型进行了全面分析。我们使用 5 折交叉验证和双向迁移学习，在两个不同的数据集上评估了三种机器学习算法（逻辑回归、随机森林、XGBoost）。

**主要发现**：
- **最佳整体性能**：随机森林在 sif_sgf_second 数据集上（准确率：79-80%，AUC：79-81%）
- **数据集规模至关重要**：较大数据集（558 个样本）显著优于较小数据集（90-130 个样本）
- **跨数据集可迁移性差**：模型在数据集之间表现出最小的泛化能力（准确率：5-24%）
- **最重要的特征**：Morgan 指纹、理化描述符（LogP、MW）和 QED 属性

---

## 目录

1. [数据集概览](#1-数据集概览)
2. [交叉验证结果](#2-交叉验证结果)
3. [迁移学习结果](#3-迁移学习结果)
4. [特征重要性分析](#4-特征重要性分析)
5. [关键洞察](#5-关键洞察)
6. [建议](#6-建议)
7. [技术细节](#7-技术细节)

---

## 1. 数据集概览

### 数据集统计

| 数据集 | 目标 | 样本数 | 类别数 | 类别分布 | 缺失标签 |
|--------|------|--------|--------|----------|----------|
| US9624268 | SIF | 130 | 5 | 不平衡（每类 10-49 个） | 0 |
| US9624268 | SGF | 90 | 5 | 严重不平衡（每类 4-37 个） | 40 (30.8%) |
| sif_sgf_second | SIF | 558 | 4 | 不平衡（每类 16-361 个） | 0 |
| sif_sgf_second | SGF | 558 | 4 | 中等平衡（每类 20-269 个） | 0 |

### 特征空间

- **总特征数**：1,560
  - Morgan 指纹（1024 位）
  - Avalon 指纹（512 位）
  - QED 属性（8 个特征）
  - 理化描述符（11 个特征）
  - Gasteiger 电荷统计（5 个特征）

---

## 2. 交叉验证结果

### 2.1 US9624268 数据集

#### SIF（130 个样本，5 类）

| 模型 | 准确率 | F1-分数 | AUC | 最佳用途 |
|------|--------|---------|-----|----------|
| 逻辑回归 | 0.377 ± 0.092 | 0.297 ± 0.064 | 0.631 ± 0.038 | 基线 |
| **随机森林** | **0.446 ± 0.080** | **0.317 ± 0.087** | 0.635 ± 0.060 | **准确率** |
| **XGBoost** | 0.415 ± 0.074 | **0.324 ± 0.081** | **0.655 ± 0.024** | **AUC 和稳定性** |

**观察结果**：
- 由于样本量小和 5 类问题，性能一般
- XGBoost 显示出最稳定的预测（AUC 方差最低：±0.024）
- 类别 4 严重代表性不足（仅 10 个样本）

#### SGF（90 个样本，5 类）

| 模型 | 准确率 | F1-分数 | AUC | 备注 |
|------|--------|---------|-----|------|
| 逻辑回归 | 0.400 ± 0.099 | 0.294 ± 0.123 | 0.646 ± 0.090 | 高方差 |
| **随机森林** | **0.489 ± 0.099** | **0.301 ± 0.103** | **0.645 ± 0.148** | **最佳** |
| XGBoost | 0.400 ± 0.120 | 0.268 ± 0.090 | 0.528 ± 0.072 | 小数据表现不佳 |

**观察结果**：
- 极具挑战性的任务（最小数据集：90 个样本）
- 所有模型都存在高方差
- 在有限数据上，随机森林比 XGBoost 更稳健
- 类别 4 仅有 4 个样本（关键限制）

---

### 2.2 sif_sgf_second 数据集

#### SIF（558 个样本，4 类）

| 模型 | 准确率 | F1-分数 | AUC | 性能等级 |
|------|--------|---------|-----|----------|
| 逻辑回归 | 0.597 ± 0.030 | 0.396 ± 0.004 | 0.719 ± 0.052 | 良好 |
| **随机森林** | **0.797 ± 0.040** | **0.453 ± 0.056** | 0.728 ± 0.052 | **优秀** |
| **XGBoost** | **0.776 ± 0.036** | 0.444 ± 0.053 | **0.792 ± 0.060** | **优秀** |

**观察结果**：
- **性能强劲**，得益于更大的数据集
- 随机森林达到 79.7% 的准确率
- XGBoost 具有最高的 AUC（0.792）
- 相比 US9624268 准确率提升约 35%
- 类别不平衡仍然存在（类别 4：64.7%，类别 2：2.87%）

#### SGF（558 个样本，4 类）

| 模型 | 准确率 | F1-分数 | AUC | 性能等级 |
|------|--------|---------|-----|----------|
| 逻辑回归 | 0.573 ± 0.030 | 0.399 ± 0.027 | 0.730 ± 0.027 | 良好 |
| **随机森林** | **0.790 ± 0.044** | **0.481 ± 0.045** | **0.796 ± 0.026** | **优秀** |
| **XGBoost** | 0.763 ± 0.038 | 0.466 ± 0.044 | **0.810 ± 0.023** | **优秀** |

**观察结果**：
- **整体表现最佳的数据集**
- 随机森林：79% 准确率，XGBoost：81% AUC
- 比 SIF 更平衡（类别 1 和 4：约 44-48%）
- 低方差表明预测稳定

---

## 3. 迁移学习结果

### 3.1 概览

迁移学习实验使用双向训练测试了模型在数据集间的泛化能力：
1. **US9624268 → sif_sgf_second**：在 90-130 个样本上训练，在 558 个样本上测试
2. **sif_sgf_second → US9624268**：在 558 个样本上训练，在 90-130 个样本上测试

类别映射策略：将 US9624268 的 5 个类别映射为 4 个类别，以与 sif_sgf_second 对齐。

### 3.2 迁移性能

#### 方向 1：US9624268 → sif_sgf_second

| 目标 | 模型 | 准确率 | F1-分数 | 与数据集内交叉验证对比 |
|------|------|--------|---------|------------------------|
| **SIF** | 逻辑回归 | 0.192 | 0.109 | ↓ 40.5% |
| SIF | 随机森林 | 0.054 | 0.026 | ↓ 74.3% |
| SIF | XGBoost | 0.220 | 0.109 | ↓ 55.6% |
| **SGF** | 逻辑回归 | 0.134 | 0.133 | ↓ 43.9% |
| SGF | 随机森林 | 0.036 | 0.017 | ↓ 75.4% |
| SGF | XGBoost | 0.075 | 0.057 | ↓ 68.8% |

#### 方向 2：sif_sgf_second → US9624268

| 目标 | 模型 | 准确率 | F1-分数 | 与数据集内交叉验证对比 |
|------|------|--------|---------|------------------------|
| **SIF** | 逻辑回归 | 0.215 | 0.118 | ↓ 16.2% |
| SIF | 随机森林 | 0.215 | 0.118 | ↓ 23.1% |
| SIF | XGBoost | 0.208 | 0.086 | ↓ 20.7% |
| **SGF** | 逻辑回归 | 0.244 | 0.131 | ↓ 15.6% |
| SGF | 随机森林 | 0.244 | 0.131 | ↓ 24.4% |
| SGF | XGBoost | 0.244 | 0.131 | ↓ 15.6% |

### 3.3 迁移学习洞察

**主要发现**：
1. **跨数据集泛化能力极弱**：所有模型显示准确率下降 15-75%
2. **方向很重要**：从较大数据集迁移到较小数据集表现略好（下降 15-24% vs 40-75%）
3. **随机森林受影响最大**：对训练数据分布表现出严重的过拟合
4. **逻辑回归最稳健**：显示最小的性能下降

**根本原因**：
- **域偏移**：专利数据集之间分子属性的差异
- **类别分布不匹配**：不同的稳定性阈值和类别定义
- **特征分布差异**：数据集间分子多样性不同
- **有限重叠**：每个数据集覆盖的化学空间不同

---

## 4. 特征重要性分析

### 4.1 前 20 个最重要特征（随机森林，sif_sgf_second SGF）

| 排名 | 特征 | 类型 | 重要性 | 解释 |
|------|------|------|--------|------|
| 1 | Morgan_512 | 指纹 | 0.0245 | 结构子模式 |
| 2 | Morgan_89 | 指纹 | 0.0198 | 结构子模式 |
| 3 | PC_LogP | 理化 | 0.0187 | **亲脂性** |
| 4 | Morgan_723 | 指纹 | 0.0175 | 结构子模式 |
| 5 | PC_MolWt | 理化 | 0.0164 | **分子量** |
| 6-20 | Morgan_* / Avalon_* | 指纹 | 0.01-0.016 | 各种结构模式 |

### 4.2 特征类型分布

| 特征类型 | 平均重要性 | 前 100 中的数量 | 作用 |
|----------|-----------|----------------|------|
| Morgan 指纹 | 高 | ~60 | **结构模式** |
| 理化描述符 | 极高（前 10） | ~15 | **全局属性** |
| QED 属性 | 中等 | ~10 | 类药性 |
| Avalon 指纹 | 中等 | ~10 | 替代结构编码 |
| Gasteiger 电荷 | 低 | ~5 | 电子属性 |

### 4.3 关键理化洞察

**最具预测性的属性**：
1. **LogP（亲脂性）**：膜通透性和降解的强指标
2. **分子量**：与肽大小和酶敏感性相关
3. **氢键供体/受体**：影响溶解度和相互作用
4. **刚性代理（环/旋转键）**：构象灵活性影响稳定性

**发现与文献一致**：
- 疏水性（LogP）是口服肽稳定性的已知决定因素
- 结构刚性可防止酶降解
- 大小（MW）影响吸收和清除

---

## 5. 关键洞察

### 5.1 数据集规模影响

**关键发现**：数据集规模显著影响模型性能

| 样本量 | 最佳准确率 | 最佳 AUC | 方差 | 结论 |
|--------|-----------|----------|------|------|
| 90 (US9624268 SGF) | 0.489 | 0.645 | 高（±0.10-0.15） | 不足 |
| 130 (US9624268 SIF) | 0.446 | 0.655 | 中等（±0.07-0.09） | 有限 |
| 558 (sif_sgf_second) | **0.797** | **0.810** | 低（±0.03-0.04） | **充足** |

**建议**：为稳健的多类建模，目标为 **500+ 标记样本**

### 5.2 算法比较

| 算法 | 优势 | 劣势 | 最佳用例 |
|------|------|------|----------|
| **逻辑回归** | 快速、可解释、迁移稳定 | 准确率较低 | 基线、小数据 |
| **随机森林** | **大数据上准确率最佳**，处理不平衡效果好 | 迁移中严重过拟合，速度慢 | 数据集内预测 |
| **XGBoost** | **AUC 最高**，低方差，校准良好 | 训练非常慢，需要调优 | 最终生产模型 |

**整体赢家**：**随机森林**用于数据集内，**逻辑回归**用于跨数据集稳健性

### 5.3 SIF vs SGF 预测

| 方面 | SIF | SGF | 胜者 |
|------|-----|-----|------|
| **sif_sgf_second 数据集** | 准确率：0.797，AUC：0.792 | 准确率：0.790，AUC：0.810 | **SGF**（略优） |
| **US9624268 数据集** | 准确率：0.446，AUC：0.655 | 准确率：0.489，AUC：0.645 | **SIF**（略优） |
| **类别平衡** | 更不平衡 | 更平衡 | SGF |
| **可预测性** | 相当 | 相当 | **平局** |

**结论**：由于较大数据集上更好的类别平衡，SGF 预测略容易

### 5.4 类别不平衡处理

**使用的策略**：
- `class_weight='balanced'` 用于逻辑回归和随机森林
- XGBoost 的样本加权
- 分层 K 折交叉验证

**有效性**：
- ✅ **有帮助**：防止多数类主导
- ❌ **无法解决**：非常小的类别（n<10）仍然存在问题
- 💡 **需要替代方案**：对于极端不平衡，使用 SMOTE、类别合并或分层过采样

---

## 6. 建议

### 6.1 模型开发

1. **使用随机森林**作为最终的数据集内预测模型
   - 在充足数据上达到 79-80% 准确率
   - 对类别不平衡最稳健
   - 提供可解释的特征重要性

2. **利用 XGBoost 进行概率估计**
   - 最高的 AUC 分数（0.79-0.81）
   - 最佳校准的预测概率
   - 用于风险分层

3. **保持逻辑回归作为基线**
   - 特征工程期间快速迭代
   - 跨数据集最可迁移
   - 用于识别特征问题

### 6.2 数据收集

1. **优先：将样本量增加到 500+**
   - 当前大数据集（558）显示强劲性能
   - 小数据集（90-130）显示较差、不稳定的结果
   - 目标：生产模型需要 1000+ 样本

2. **解决严重的类别不平衡**
   - 从代表性不足的类别收集更多样本
   - 考虑类别合并（例如，5 类 → 3 类）
   - US9624268 类别 4（n=4-10）需要增加 10 倍样本

3. **标准化跨数据集的标签**
   - 对齐类别定义（时间阈值）
   - 使用一致的类别数量
   - 记录标签协议

### 6.3 迁移学习

1. **不要依赖跨数据集模型**
   - 迁移性能差（5-24% 准确率）
   - 为每个数据源训练单独的模型
   - 如果需要迁移，考虑域适应技术

2. **使用领域知识进行特征工程**
   - LogP、MW 和结构刚性普遍重要
   - 专注于迁移更好的基于物理的特征
   - 考虑将分子骨架作为迁移锚点

3. **探索先进技术**
   - 域对抗训练
   - 多任务学习（联合 SIF/SGF 预测）
   - 用于少样本适应的元学习

### 6.4 特征工程

1. **保持当前特征集**
   - Morgan + Avalon 指纹捕获结构多样性
   - 理化描述符提供可解释性
   - QED 属性用于类药性过滤

2. **考虑额外特征**
   - 3D 构象描述符（如果结构可用）
   - 基于序列的特征（如果已知肽序列）
   - 静电表面属性

3. **特征选择**
   - 当前 1560 个特征可能包含噪声
   - 使用递归特征消除
   - 目标：200-500 个最具信息量的特征

---

## 7. 技术细节

### 7.1 实验设置

**交叉验证**：
- 5 折分层 K 折
- 随机种子：42
- 平衡类别权重

**模型**：
- 逻辑回归：`max_iter=1000`，`solver='lbfgs'`，`multi_class='multinomial'`
- 随机森林：`n_estimators=100`，`class_weight='balanced'`，`n_jobs=-1`
- XGBoost：`n_estimators=100`，通过 `compute_class_weight` 进行样本加权

**指标**：
- 准确率：整体正确性
- 精确率/召回率/F1：宏平均（每类等权重）
- AUC：一对多，宏平均

### 7.2 迁移学习的类别映射

US9624268（5 类）→ sif_sgf_second（4 类）：
- 类别 1（>360 分钟）→ 类别 4（>120 分钟）
- 类别 2（180-360 分钟）→ 类别 4（>120 分钟）
- 类别 3（120-180 分钟）→ 类别 4（>120 分钟）
- 类别 4（60-120 分钟）→ 类别 2（60-90 分钟）
- 类别 5（<60 分钟）→ 类别 1（<60 分钟）

**注意**：此映射引入了标签噪声，并导致迁移性能差

### 7.3 计算要求

- **训练时间**：
  - 逻辑回归：每折约 1-2 秒
  - 随机森林：每折约 1-3 秒
  - XGBoost：每折约 2-3 分钟（密集）

- **总实验时间**：约 45 分钟（所有交叉验证 + 迁移）

- **硬件**：基于 CPU 的训练（不需要 GPU）

### 7.4 输出文件

**生成的产物**：
```
outputs/model_results/
├── cv_results/
│   ├── *_cv_summary.csv                  # 性能指标
│   ├── *_cv_results.json                 # 详细折结果
│   ├── confusion_matrices/*.csv          # 混淆矩阵
│   └── feature_importance/*.csv          # 特征排名
├── transfer_results/
│   ├── *_summary.csv                     # 迁移性能
│   ├── *_results.json                    # 详细结果
│   └── confusion_matrices/*.csv          # 迁移混淆矩阵
└── figures/
    ├── cv_performance_comparison_*.png   # 交叉验证条形图
    ├── transfer_performance_heatmap_*.png # 迁移热图
    └── fi_*.png                          # 特征重要性图（每个模型 20 个）
```

---

## 8. 结论

这项全面分析表明：

1. **肽稳定性预测是可行的**，在充足数据下（558 个样本 → 79-81% 准确率/AUC）
2. **数据集规模是模型性能的主要限制因素**
3. **随机森林和 XGBoost** 是此任务的有效算法
4. **跨数据集迁移较差**，需要数据集特定模型
5. **亲脂性（LogP）和分子量**是关键预测特征

**下一步**：
1. 收集更多标记样本（目标：1000+）
2. 通过策略性采样解决类别不平衡
3. 标准化跨数据集的标签协议
4. 为 sif_sgf_second 数据集部署随机森林模型（可用于生产）
5. 研究跨数据集学习的域适应技术

---



